# Настройка

Этот репозиторий представляет собой пример интеграции ClickHouse и Kafka с использованием Docker и Node.js.

## Запуск приложения

### Шаг 1: Запуск ClickHouse и Kafka

1. Убедитесь, что у вас установлен Docker.
2. Склонируйте этот репозиторий.
3. Запустите контейнеры ClickHouse и Kafka с помощью следующей команды в корневой директории проекта:
   ```bash
   docker-compose up -d

### Шаг 2: Подключеник к clickHouse
Подключитесь к ClickHouse с помощью следующих учетных данных:

1. Подключитесь к ClickHouse с помощью следующих учетных данных:
- Логин: myuser
- Пароль: mypassword
- Порт: 8123

### Шаг 3: Выполнение SQL-скриптов
1. В клиенте ClickHouse выполните SQL-скрипты из папки migrations, чтобы создать необходимые таблицы и индексы.

### Шаг 4: Настройка скрипта для отправки сообщений в Kafka

1. Откройте файл script.js в корневой директории проекта.
2. Установите желаемое количество сообщений, которые вы хотите отправить в Kafka, изменяя переменную totalCount. (по умолчанию 2_500_000)

### Шаг 5: Запуск скрипта

- node script.js


# Доп информация

### Вычитывание из Kafka и инсерт в ClickHouse
-  Получилось вычитывать из кафки батчами по несколько тысяч записей и вставлять в ClickHouse при одном топике и 1 консюмере. Ничего не упало

### Дамп бд постгреса в кликхаус
- Получилось сдампить только с помощтю csv формата, но 90% данных потерялось при вставке с ошибками

#### Варианты дампа из постгреса в кликхаус:
- Написать сервис который будет селектить из постгреса и писать в кафку, чтоб перетащить данные в кликхаус
- Использовать дебезиум для чтение данных из таблицы постгреса и отправки их в кафку


### Сравнение производительности запросов в PostgreSQL и ClickHouse

#### sql query

```python
SELECT
    count(*) AS total_rows,
    sum(CASE WHEN ban THEN 1 ELSE 0 END) AS total_banned_users,
    sum(CASE WHEN reg THEN 1 ELSE 0 END) AS total_registered_users,
    count(DISTINCT email) AS total_unique_emails,
    count(DISTINCT uuid) AS total_unique_uuids,
    max('dateReg') AS max_date_reg,
    max('dateFtd') AS max_date_of_first_deposit,
    sum(bets) AS total_bets,
    sum(wins) AS total_wins,
    sum(refunds) AS total_refunds,
    sum(rollbacks) AS total_rollbacks,
    sum(ggr) AS total_ggr
from "user_data"
```

- Выполнение запроса в PostgreSQL заняло 14 секунд (после кеширования), в то время как в ClickHouse запрос выполнился за секунду.
- Предлагаю дать аналитикам доступ к кликхаусу чтоб они могли выполнить свои запросы и посмотрить на реальную, боевую производительность на stage.
- Размер данных по сравнению с постгресом сократился в два раза

#### Варианты улучшения производительности:
- Сделать ORDER BY по другом полю
- Сделать индексы
- Еще способы улучшения: https://habr.com/ru/articles/514840/